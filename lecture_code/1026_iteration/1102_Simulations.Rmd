---
title: "1102_Simulations"
author: "Ze Li"
date: "2023-11-02"
output: github_document
---

```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Load key packages.

```{r}
library(tidyverse)
```


Set seed for reproducibility.

```{r}
set.seed(12345)
```



## Simulate sample mean and sd

Here's an old function:

```{r}
sim_mean_sd = function(n_obs, mu = 5, sigma = 1) {
  
  x_vec = rnorm(n = n_obs, mean = mu, sd = sigma)

  tibble(
    mean = mean(x_vec),
    sd = sd(x_vec)
  )
  
}

```

Let's see what this does.

```{r}
sim_mean_sd(n_obs = 30)
```

## Let's iterate to see how this works UNDER REPEATED SAMPLING!!!

```{r}
output = vector("list", length = 100)

for (i in 1:100) {
  
  output[[i]] = sim_mean_sd(n_obs = 30)
  
}

sim_results = 
  bind_rows(output)

sim_results |> 
  ggplot(aes(x = mean)) + geom_density()

sim_results |> 
  summarize(
    mu_hat = mean(mean), 
    sd_hat = sd(mean)
  )
```

use a map function


```{r}
sim_result_df =
  expand_grid(
    sample_size = c(30, 60, 120, 240),
    iter = 1:1000
  ) |> 
  mutate(estimate_df = map(sample_size, sim_mean_sd)) |> 
  unnest(estimate_df)

sim_result_df |> 
  mutate(
    sample_size = str_c("n = ", sample_size),
    sample_size = fct_inorder(sample_size)
  ) |> 
  ggplot(aes(x = sample_size, y = mean)) + 
  geom_boxplot()

```



## SLR simple linear regression

Goal is to write a function that simulates data and then fits a regression; then repeat to look at the distribution of estimated coefficients. 

```{r}
beta_0 = 2
beta_1 = 3

sim_data = 
  tibble(
    x = rnorm(n = 30, mean = 1, sd = 1), 
    y = beta_0 + beta_1 * x + rnorm(30, mean = 0, sd = 1)
  )

ls_fit = lm(y ~ x, data = sim_data)
ls_fit

sim_data |> 
  ggplot(aes(x = x, y = y )) + 
  geom_point()
```


let's wrap this in a function

```{r}
sim_slr = function(n_obs, beta_0 = 2, beta_1 = 3) {
  
  sim_data = 
    tibble(
      x = rnorm(n = n_obs, mean = 1, sd = 1), 
      y = beta_0 + beta_1 * x + rnorm(n_obs, mean = 0, sd = 1)
    )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta0_hat = coef(ls_fit)[1],
    beta1_hat = coef(ls_fit)[2]
  )
  
}

sim_slr(n_obs = 30)

```

run this a whole bunch of times

```{r}
sim_results_df = 
  expand_grid(
    sample_size = 30,
    iter = 1:1000
  ) |> 
  mutate(estimate_df = map(sample_size, sim_slr)) |> 
  unnest(estimate_df)
```

Let's look at results.


```{r}
sim_results_df |> 
  summarize(
    mean_b0_hat = mean(beta0_hat),
    mean_b1_hat = mean(beta1_hat)
  )

sim_results_df |> 
  ggplot(aes(x = beta0_hat)) + 
  geom_histogram()

sim_results_df |> 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point()

```




